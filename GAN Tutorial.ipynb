{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GAN on Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb #if you dont have wandb setup, please install it and ask divi for the login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# so you dont have to restart kernel if you make changes to other files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part of this notebook, we are going to create the Generator model and the Descriminator model.\n",
    "\n",
    "For a simple example of how to do this, check models.py in the accompanying repo. The models in this file are just one layer -- we would like to train a model that is larger than this so that it will do better.\n",
    "\n",
    "## Generator\n",
    "This is the model that will take in random noise and output an image. We will decide the size of the random noise and images later on in this notebook, so just make sure your model will take in a vector of size `input_length` and output an image of size `output_length`. Ensure your model has multiple layers, but the design of the rest of the model is up to you. If you choose to train on larger images, (Ex: 64x64 or 128x128) consider using some deconvolutional layers.\n",
    "\n",
    "## Descriminator\n",
    "This is the model that will take in an image and output a probability that this image is real. Thus, it will take in an image of size `output_length` and output 1 value. You can think of this as just a binary classification model (therefore we will train on binary cross entropy). As before, create your Discriminator model with multiple layers and the correct input and output sizes. If you choose to train on larger images, (Ex: 64x64 or 128x128) consider using some convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_length: int, output_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        # TODO instantiate the layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO pass x through the layers + activations and return it\n",
    "        return\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # TODO instantiate the layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO pass x through the layers + activations and return it\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset\n",
    "For this notebook, we are going to train on the CelebA dataset in order to create pictures of faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CelebA, MNIST\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "# TODO fill in these parameters with whatever you want\n",
    "image_size = None # should be a tuple\n",
    "batch_size = None\n",
    "\n",
    "# first we create some transforms to normalize our data and resize it to the shape that we specify\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# this will download the celeba dataset for you, if it doesn't work\n",
    "# then find it online\n",
    "dataset = MNIST(\"~/datasets\", train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at some of the images we will be training on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples, label = next(iter(data_loader))\n",
    "sample = samples[0].numpy().transpose(1,2,0) #pytorch has channels as first dim, we need it as last dim\n",
    "\n",
    "plt.imshow(sample, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded our dataset and decided our image size, lets instantiate our generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose the size of the noise vector to give to our generator\n",
    "input_length = None\n",
    "\n",
    "# Instantiate Models\n",
    "generator = None\n",
    "discriminator = None\n",
    "\n",
    "# It is always good to print out your model \n",
    "# to make sure it is what you are expecting\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check to make sure your shapes are correct\n",
    "outputs = generator(torch.zeros(batch_size, input_length))\n",
    "outputs = outputs.view(batch_size, 1, image_size[0], image_size[1])\n",
    "fake_prob = discriminator(outputs)\n",
    "\n",
    "# visualize the image created by an untrained generator, this should look like noise\n",
    "output = outputs[0].detach().numpy().transpose(1,2,0)\n",
    "plt.imshow(output, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "We need two optimizers to train our two models. Choose the learning rate for these below. Feel free to experiment with these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_learning_rate = None\n",
    "discriminator_learning_rate = None\n",
    "\n",
    "# Create optimizers with the learning rates of your chooosing\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=generator_learning_rate)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=discriminator_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now we have everything we need to train our GAN! Except the training loop. Checkout `train.py` and fill in the missing code. Once you're done, run the cells below to train your GAN and checkout wandb to see how it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "\n",
    "wandb.init(project='gan-notebook')\n",
    "\n",
    "# fill in a name to keep track of which wandb runs are yours\n",
    "your_name = None\n",
    "wandb.config.name = your_name\n",
    "\n",
    "# fill in the number of epochs you want to train for\n",
    "epochs = 10\n",
    "wandb.config.epochs = epochs\n",
    "\n",
    "trained_generator, trained_discriminator = train(generator, discriminator, \n",
    "                                                 generator_optimizer, discriminator_optimizer, \n",
    "                                                 data_loader, batch_size,\n",
    "                                                 input_length, image_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
